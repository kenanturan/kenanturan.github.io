<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Human Factor Vulnerability in Facility Security | Taktik Eğitim Akademisi</title>
    <link rel="icon" href="../assets/contact_logo.png" type="image/png">
    <link rel="stylesheet" href="../style.css?v=3">

    <!-- Open Graph / Social Media Meta Tags -->
    <meta property="og:title" content="Human Factor Vulnerability in Facility Security | Taktik Eğitim Akademisi" />
    <meta property="og:description"
        content="Why does security fail despite technological investments? An analysis on the human factor." />
    <meta property="og:image" content="../assets/logoo.png" />
    <meta property="og:url" content="" />
    <meta property="og:type" content="article" />
    <meta name="twitter:card" content="summary_large_image" />

<body>
    <nav class="navbar">
        <div class="container">
            <a href="index.html" class="logo"><img src="../assets/logo.png" alt="Taktik Eğitim Akademisi"></a>
            <ul class="nav-links">
                <li><a href="index.html" class="nav-link">Home</a></li>
                <li><a href="approach.html" class="nav-link">Approach</a></li>
                <li><a href="academy.html" class="nav-link">Academy</a></li>
                <li><a href="academic.html" class="nav-link">Publications</a></li>
                <li><a href="expertise.html" class="nav-link">Expertise</a></li>
                <li><a href="analysis.html" class="nav-link active">Analysis</a></li>
                <li><a href="contact.html" class="nav-link">Contact</a></li>
            </ul>
            <div class="lang-switch">
                <a href="../analysis-human-factor.html" class="lang-link">TR</a>
                <span class="lang-separator">|</span>
                <a href="#" class="lang-link active">EN</a>
            </div>
            <div class="menu-toggle" id="mobile-menu">
                <span class="bar"></span>
                <span class="bar"></span>
                <span class="bar"></span>
            </div>
        </div>
    </nav>

    <main>
        <section class="section content-section">
            <div class="container" style="max-width: 800px;">
                <div
                    style="display: flex; justify-content: space-between; align-items: center; margin-bottom: var(--space-sm);">
                    <span class="text-gold"
                        style="font-size: 0.9rem; letter-spacing: 0.1em; text-transform: uppercase;">Case
                        Study</span>
                    <span
                        style="font-family: var(--font-display); font-size: 0.95rem; color: var(--text-muted); opacity: 0.8;">Dec
                        25, 2025</span>
                </div>
                <h1
                    style="font-family: var(--font-display); font-size: 2.5rem; line-height: 1.2; margin-bottom: var(--space-lg);">
                    Human Factor Vulnerability in Facility Security
                </h1>

                <div style="font-size: 1.1rem; line-height: 1.8; color: var(--text-main); text-align: justify;">

                    <h2
                        style="font-size: 1.5rem; color: var(--accent-gold); margin-top: var(--space-lg); margin-bottom: var(--space-sm);">
                        Why Does Security Start with Technology and End with Humans?</h2>

                    <p>When it comes to facility security, the first reflex is often to turn to technology. More
                        advanced cameras, more sensitive sensors, more complex software... As investment lists grow, it
                        is assumed that security increases in the same measure. Yet reality in the field often
                        frustrates this linear relationship.</p>

                    <p>No matter how advanced security systems are, they are limited by the human who uses, interprets,
                        and makes sense of them. Unless the eye watching the camera feed, the mind evaluating the alarm,
                        and the will applying the procedure come into play, technology remains merely a passive
                        infrastructure. Therefore, even if security begins as a technical system, in practice it is
                        completed by human behavior.</p>

                    <p>The human factor is often addressed only through "error." Yet the real issue is not error; it is
                        <strong>the relationship the human establishes with the system.</strong> The same personnel can
                        show high awareness in the right context and with the right support; while in a poorly designed
                        system, they may begin to automate and stop questioning even the most basic tasks. at this
                        point, vulnerability arises not from the person's intent, but from how the system positions the
                        human.
                    </p>

                    <p>A common feature of many vulnerabilities experienced in facility security is that they go
                        unnoticed despite the presence of technology. The alarm rang but was ignored. The camera
                        recorded but no one looked. The procedure is written but has lost its meaning within the
                        routine. These examples show not the failure of technology; but how the human "got used" to it
                        within the system.</p>

                    <p>Therefore, when the human factor is defined as the weakest link in the security chain, the
                        problem is looked for in the wrong place. The human produces vulnerability not because they are
                        weak; but because <strong>they are placed into the system with wrong assumptions.</strong>
                        Reading security only through hardware and software makes this truth invisible.</p>

                    <p>Facility security seems to start with technology, but in fact, it starts with humans and ends
                        with humans. What makes security sustainable is not how advanced the systems are, but how
                        compatible these systems are designed with human behavior. When the human factor is not read
                        correctly, even the most expensive security infrastructure remains merely a cost item.</p>

                    <h2
                        style="font-size: 1.5rem; color: var(--accent-gold); margin-top: var(--space-lg); margin-bottom: var(--space-sm);">
                        What "Human Factor" Is and Is Not?</h2>

                    <p>When a disruption occurs in facility security, the first sentence spoken is usually the same:
                        <strong>"Human error."</strong> This expression closes the issue rather than defining it.
                        because when "human factor" is mentioned, individual carelessness, non-compliance with rules, or
                        personal inadequacy is often implied. Yet this approach overlooks the greater part of the issue.
                    </p>

                    <p>The human factor is not a mistake made by a single person alone. Rather, it is the natural result
                        of the relationship the human establishes with the system they work in. The same person may
                        perform completely differently in a different environment, within a different organization.
                        Therefore, reading the human factor only through individual error means looking for security
                        vulnerability in the wrong place.</p>

                    <p>Another common misconception is equating the human factor with intent. Yet the majority of
                        problems encountered in facility security stem not from deliberate violations, but from habits
                        and routines. Repeated tasks eliminate questioning over time. The procedure is applied, but why
                        it is applied is forgotten. At this point, the human begins to produce risk not because they are
                        faulty; but because <strong>they have gotten used to it.</strong></p>

                    <p>The human factor is also not solely a "low qualification" issue. Even educated, experienced, and
                        well-intentioned personnel can produce vulnerability within a poorly designed system. Complex
                        technologies, difficult-to-understand interfaces, and procedures that do not overlap with real
                        workflow remove the human from being a part of the system and turn them into an element carrying
                        the system's burden.</p>

                    <p>Therefore, the human factor should not be labeled as the weak link of the security chain. The
                        human is the final link of the system. When previous links are not designed correctly, it is
                        unrealistic to expect flawless performance from the final link. What is called human factor
                        vulnerability is often a delayed reflection of design, training, and management decisions.</p>

                    <p>Reading the human factor correctly requires giving up searching for a culprit. The question
                        should be not "who made a mistake?" but "why was this mistake possible?" Unless this question is
                        asked, similar vulnerabilities reappear again and again with same persons within same systems.
                        Not because the human hasn't changed; but because the system hasn't reproduced itself.</p>

                    <p>In facility security, the human factor is neither an excuse nor an unavoidable defect. When
                        understood correctly, it is one of the most predictable and improvable components of the system.
                        But for this, it is necessary to see the human not as the problem itself, but as part of the
                        solution.</p>

                    <h2
                        style="font-size: 1.5rem; color: var(--accent-gold); margin-top: var(--space-lg); margin-bottom: var(--space-sm);">
                        Technology–Human Mismatch</h2>

                    <p>The problem between technology and human in facility security is often explained as "technology
                        insufficient" or "personnel insufficient." Yet a significant part of vulnerabilities experienced
                        in practice stems from these two <strong>not being designed suitably for each other.</strong>
                        The system is working, personnel are there too; but the two are not speaking the same language.
                    </p>

                    <p>Security technologies are often designed based on ideal scenarios. It is assumed that the user is
                        attentive, knows the procedure perfectly, and makes the right prioritization when the alarm
                        comes. Reality in the field is messier. Multiple tasks at the same time, distractors, time
                        pressure, and routines are in play. In this environment, technology positions itself not
                        according to the human's capacity; but the human positions themselves according to the burden of
                        technology.</p>

                    <p>The first symptom of mismatch is complexity. Multi-layered screens, warnings whose meanings are
                        unclear, and excessive alarms dull the personnel's attention instead of increasing it. After a
                        while, the system turns into "background noise." The alarm rings but loses its property of being
                        an alarm. The camera records but is not watched. The system works; it does not produce security.
                    </p>

                    <p>At this point, what is frequently called "user error" appears. Yet often there is not an error,
                        but a <strong>predictable behavior.</strong> The human learns not to take seriously a system
                        they cannot make sense of or that constantly produces false alarms. This learning is not a
                        conscious violation; it is an adaptation reflex. The system does not train the human; the human
                        begins to tolerate the system.</p>

                    <p>Another mismatch is between procedures and real workflow. Security steps that look flawless on
                        paper may not be applicable in the field. In this situation, personnel face two options: Either
                        follow the procedure exactly in a way that disrupts work or stretch the procedure to carry out
                        the work. Often the second path is chosen. Thus, the system turns into a structure that is
                        bypassed without being noticed.</p>

                    <p>The most invisible result of technology–human mismatch is the shift in responsibility perception.
                        when personnel fall into the thought "the system exists, it will catch it," individual attention
                        withdraws. Technology ceases to be a supportive tool; it becomes a guarantor expected to take
                        over the mental load. However, technology does not decide, it only produces data. The decision
                        point is still the human; but this truth is often forgotten.</p>

                    <p>Therefore, in facility security, the problem is not the presence or absence of technology; but
                        <strong>how the human is left alone</strong> with that technology. Every system established
                        without taking into account human capacity, attention span, and decision-making style produces
                        its own vulnerability. At the point where technology does not strengthen the human, it slows
                        them down and blinds them.
                    </p>

                    <p>A security system incompatible with humans is fragile no matter how advanced it is. Because
                        vulnerability is born not from outside the system; but from within daily usage. And these
                        vulnerabilities usually start not with an attack, but with an ordinary shift day.</p>

                    <h2
                        style="font-size: 1.5rem; color: var(--accent-gold); margin-top: var(--space-lg); margin-bottom: var(--space-sm);">
                        Lack of Training or Illusion of Training?</h2>

                    <p>One of the defense sentences frequently heard when a vulnerability appears in facility security
                        is this: "The personnel were trained." This statement is often true; but at the same time
                        misleading. Because being trained does not always mean being ready.</p>

                    <p>A large part of security training focuses on transferring information. Procedures are explained,
                        how devices work is shown, dos and don'ts are listed. Training is completed, attendance list is
                        signed. There is no problem on paper. However, in the field, how much of this information
                        actually turns into usage is rarely questioned.</p>

                    <p>The fundamental problem here is that training is often <strong>disconnected from real
                            context.</strong> The training environment is calm; the field environment is not. There is
                        time in training; often there is not in the field. The scenario is clear in training; situations
                        are blurry in the field. This disconnect causes personnel to do what they are <strong>used
                            to</strong>, not what they know, in a moment of crisis.</p>

                    <p>Another common illusion is that giving training once is sufficient. Yet learning in security is
                        not linear. Information that is not repeated, updated, and discussed dulls rapidly. Even if
                        personnel remember the procedure, they forget why the procedure was constructed that way. When
                        the "why" is forgotten, the application also loses its meaning.</p>

                    <p>The most dangerous result of the training illusion appears silently in the field. Personnel
                        define themselves as "trained" but avoid making decisions in an uncertain situation. Because
                        training taught them what to do; <strong>not when they should question.</strong> In this case,
                        training provides a kind of security comfort instead of producing awareness.</p>

                    <p>Another problem is that training is one-way. There is a teller, there is a listener. However,
                        what is truly valuable in security is the personnel asking questions, voicing hesitations, and
                        being able to talk about gray zones. When these areas are not discussed, training looks flawless
                        but becomes fragile. Because difficulties encountered in the field were never articulated in the
                        training hall.</p>

                    <p>The difference between lack of training and illusion of training appears exactly here. Missing
                        training is noticed; demanded. Illusion of training is not noticed; because everyone thinks they
                        have done their duty. This illusion produces a vulnerability as silent and expensive as
                        technological investments.</p>

                    <p>Effective training in facility security does not make personnel flawless. But it enables
                        personnel to see <strong>in which situation they are more open to making mistakes.</strong>
                        Training gains meaning when it starts producing questions rather than giving answers; when it
                        provides thought discipline rather than making procedures memorized. Otherwise, training does
                        not increase security; it only produces the feeling that it is safe.</p>

                    <h2
                        style="font-size: 1.5rem; color: var(--accent-gold); margin-top: var(--space-lg); margin-bottom: var(--space-sm);">
                        Motivation, Habit, and Routine Blindness</h2>

                    <p>Vulnerabilities in facility security often do not emerge as a result of a sudden error or
                        dramatic negligence. On the contrary, they form through a silent and slow process. Nothing
                        happens for days, weeks, months. The system works, shifts are completed, reports are closed.
                        Precisely this continuity produces the hardest to notice but most dangerous vulnerability:
                        routine blindness.</p>

                    <p>The human mind adapts rapidly to repeating situations. This adaptation facilitates daily life;
                        but it is risky when it comes to security. The same people pass through the same door every day,
                        the same alarm gives false signals repeatedly, the same camera image does not change for hours.
                        Over time, the "unusual" becomes usual. There is no threat because none has appeared until
                        today.</p>

                    <p>Motivation plays a critical role at this point. Security personnel often do not see the result of
                        the work they do. Success is invisible; because nothing happening is not recorded as success.
                        This situation erodes the meaning of the work over time. Personnel do their duty but stop
                        questioning why they do it. Security ceases to be a conscious activity; turns into a mechanical
                        routine.</p>

                    <p>One of the clearest indicators of routine blindness is alarm fatigue. Systems that constantly
                        give warnings but rarely point to a real situation dull personnel's reflexes. Signals examined
                        carefully at first become background noise over time. The alarm rings; but has no counterpart in
                        the mind. At this point, the problem is not the personnel's indifference; but the system failing
                        to take human behavior into account.</p>

                    <p>Habits affect not only attention but also the courage to make decisions. In a system working
                        without problems for a long time, the desire to "go out of the ordinary" decreases. Even if a
                        suspicious situation is noticed, the worry of "raising a false alarm" becomes dominant. Ignoring
                        instead of intervening seems like the option causing the least trouble. This choice is often not
                        conscious; it is a learned behavior.</p>

                    <p>Routine blindness remains unsolved when addressed as an individual vulnerability. Because
                        everyone working in the same environment under the same conditions develops similar behavior
                        patterns. Therefore, the issue cannot be solved with calls to "be more careful." Attention is
                        fed by motivation and meaning. When meaning is lost, even the most experienced personnel become
                        blind.</p>

                    <p>Sustainable awareness in facility security is possible not by eliminating routine completely; but
                        by <strong>consciously disrupting</strong> the routine. Unexpected questions, small scenarios,
                        short feedbacks, and reminders recalling cause-effect relationships reduce blindness. But when
                        these are not done, the system silently loosens within itself.</p>

                    <p>Motivation loss, habit, and routine blindness are not detected like technical failures. Yet their
                        impact is far deeper, because they erode security from the inside. And by the time they are
                        noticed, it is often too late.</p>

                    <h2
                        style="font-size: 1.5rem; color: var(--accent-gold); margin-top: var(--space-lg); margin-bottom: var(--space-sm);">
                        Authority, Responsibility, and the Ownership Problem</h2>

                    <p>Many vulnerabilities in facility security arise neither from technology nor directly from human
                        error. The real fracture forms in the gap between authority and responsibility. A task exists,
                        but its boundaries are unclear. Authority is defined, but whether it will be backed is
                        uncertain. Over time, this uncertainty produces one of the quietest yet most persistent
                        vulnerabilities.</p>

                    <p>Security personnel often face this dilemma: <strong>“I can intervene — but should I?”</strong>
                        Authority exists on paper, but who will bear the cost of the decision is unclear. At this point,
                        personnel begin to weigh not the threat, but whether they will personally carry the risk.
                        Security reflexes give way to self-protection.</p>

                    <p>Responsibility is often fragmented as well. When an incident occurs, everyone points to part of
                        the process, but no one owns the whole. There is a camera, but someone else watches it. An alarm
                        sounds, but another evaluates it. Procedures exist, but one person applies them alone. This
                        fragmentation makes the security chain fragile. Everyone did their job — but no one owned the
                        outcome.</p>

                    <p>Ownership is different from task definition. Doing a job and owning its result are not the same.
                        In facility security, many personnel meet minimum expectations. This is rarely conscious
                        indifference; it is learned behavior. In environments where initiative is not rewarded and
                        mistakes are personalized, ownership naturally retreats.</p>

                    <p>Authority–responsibility imbalance becomes most visible in gray areas. There is no clear
                        violation, only discomfort. Procedures offer no clear answer. Personnel must choose between
                        protecting the system and protecting themselves. Quiet withdrawal is often chosen, because
                        “doing nothing” is the easiest decision to explain later.</p>

                    <p>Over time, this becomes institutional language: <strong>“Not my job,”</strong>
                        <strong>“management will handle it,”</strong> <strong>“the system will catch it.”</strong> These
                        phrases are not open confessions of vulnerability, but strong indicators. Security culture is
                        measured by how easily such phrases are spoken. Where ownership weakens, technology and
                        procedures stand alone.
                    </p>

                    <p>This gap cannot be closed by training alone. It is filled by leadership behavior and daily
                        practice. Who is supported after a decision, what lessons are extracted, and how mistakes are
                        handled determine future behavior. Lived experience teaches more than written rules.</p>

                    <p>True ownership in facility security does not emerge by saying “take initiative.” Personnel must
                        know they will not be abandoned when they make reasonable, justified decisions. Without this
                        trust, even the most experienced people narrow their boundaries over time. In uncertainty, the
                        safest place becomes invisibility.</p>

                    <p>When authority, responsibility, and ownership are misaligned, human-factor vulnerability becomes
                        inevitable — not due to human inadequacy, but due to how much space the system gives. Security
                        strengthens only where responsibility is shared and decisions are not isolated.</p>

                    <h2
                        style="font-size: 1.5rem; color: var(--accent-gold); margin-top: var(--space-lg); margin-bottom: var(--space-sm);">
                        A Typical Vulnerability Reading</h2>
                    <p style="font-style: italic; color: var(--text-muted);">(Not One Person, but a Chain)</p>

                    <p>Many vulnerabilities in facility security look surprisingly “normal” in hindsight. There is a
                        shift, systems are running, personnel are present. There is no obvious negligence or deliberate
                        violation. Vulnerability forms precisely within this ordinariness.</p>

                    <p>It usually begins with a small deviation. Something that might normally draw attention is
                        accepted as ordinary, because similar situations occurred before without consequence. This first
                        decision is rarely conscious risk-taking; it is habit. No one thinks “I am taking a risk” — they
                        simply avoid disrupting the flow.</p>

                    <p>Then the system enters. Cameras record, alarms signal, software flags something. But these
                        signals may have produced false alarms many times before. Personnel are conditioned to filter
                        rather than evaluate them. The system works, but meaning does not.</p>

                    <p>Next comes the procedure. On paper, it defines what to do. But real conditions do not fully match
                        it. Time is limited, tasks overlap. The procedure is not followed exactly; it is bent. This
                        bending is not violation, but an attempt to keep work moving.</p>

                    <p>At this point, authority–responsibility quietly enters. A decision is possible, but its cost is
                        unclear. Fear of personal liability outweighs security instinct. Monitoring is chosen over
                        intervention. Monitoring slowly becomes synonymous with doing nothing.</p>

                    <p>There is no single moment where one can say, “the mistake is here.” Each step feels like a
                        natural continuation of the previous one. Everyone acted reasonably from their perspective. Yet
                        when the chain completes, the outcome is clear: the system has been neutralized through human
                        behavior.</p>

                    <p>These vulnerabilities are often noticed only after an incident or by an external observer. Until
                        then, everything feels normal. Vulnerability is not a rupture, but an accumulation.</p>

                    <p>For this reason, vulnerability analysis does not begin with blame. The real question is not “who
                        did it?” but “why did this chain never break?” Because under similar conditions, it will form
                        again. Change the people, keep the system and habits — and the result remains the same.</p>

                    <p>The key lesson is this: vulnerabilities in facility security rarely grow from sudden external
                        attacks, but from small internal tolerances — often born of good intentions.</p>

                    <h2
                        style="font-size: 1.5rem; color: var(--accent-gold); margin-top: var(--space-lg); margin-bottom: var(--space-sm);">
                        Where Is the Real Problem? People or the System?</h2>

                    <p>When a vulnerability appears in facility security, the first question almost always is:
                        <strong>“Who made the mistake?”</strong> This is understandable. Uncertainty is uncomfortable
                        and demands quick explanation. But it often looks in the wrong direction. Many security problems
                        are too layered to be explained by a single person’s error.
                    </p>

                    <p>The human factor is the visible face of vulnerability. The operator who ignores the alarm or
                        bends the procedure is easily pointed out. Yet these individuals often perform the role the
                        system assigns them. Human behavior does not emerge in a vacuum; it is shaped by structure.</p>

                    <p>The system, by contrast, is rarely questioned. It “exists.” It has been purchased, installed,
                        commissioned. It appears to work. How it interacts with humans, what behaviors it encourages, or
                        how it guides attention is rarely examined — even though many vulnerabilities originate there.
                    </p>

                    <p>If a system demands constant vigilance, flawless interpretation, and perfect decisions, but
                        provides unclear authority, weak feedback, and unrealistic workloads, the problem is not human
                        inadequacy. It is a design that assumes humans are something they are not — and that assumption
                        eventually collapses.</p>

                    <p>Thus, the question “people or system?” is incomplete. The real question is: <strong>How does this
                            system push people to behave?</strong> Vulnerability often arises not from wrong behavior,
                        but from <strong>expected behavior.</strong> Routinization, lack of questioning, risk avoidance
                        — these are not personal flaws, but reflexes quietly taught by the system.</p>

                    <p>Seeing the system only as technology and procedures hides this truth. The system is also
                        management style, feedback culture, and response to error. Who is supported after decisions,
                        what is ignored, what is rewarded — all are part of the system.</p>

                    <p>Human-factor vulnerability should not be framed as fate. Humans are the most variable but also
                        the most improvable component of security systems. But improvement does not come from “be more
                        careful” warnings. It comes from human-centered design: how people work, tire, adapt, and become
                        blind. Any system built without asking these questions carries its vulnerability within it.</p>

                    <p>In the end, the real issue in facility security is not choosing between people or systems. It is
                        thinking about them separately. Security must not be a structure that survives despite human
                        error, but one that stands by <strong>accounting for human reality.</strong> Otherwise, even the
                        most advanced technology can be quietly rendered ineffective during an ordinary shift.</p>

                </div>

                <div
                    style="margin-top: var(--space-xl); border-top: 1px solid var(--border-subtle); padding-top: var(--space-md); display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 1rem;">
                    <a href="analysis.html"
                        style="color: var(--accent-gold); text-decoration: none; display: inline-flex; align-items: center; gap: 8px; font-size: 0.95rem; transition: opacity 0.3s ease;">
                        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none"
                            stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <line x1="19" y1="12" x2="5" y2="12"></line>
                            <polyline points="12 19 5 12 12 5"></polyline>
                        </svg>
                        Back to Analysis
                    </a>

                    <div style="display: flex; gap: 15px; align-items: center;">
                        <span style="font-size: 0.9rem; color: var(--text-muted);">Share:</span>

                        <!-- LinkedIn -->
                        <button
                            onclick="window.open('https://www.linkedin.com/sharing/share-offsite/?url=' + encodeURIComponent(window.location.href), '_blank', 'width=600,height=600');"
                            class="share-action" title="Share on LinkedIn">
                            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24"
                                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                stroke-linejoin="round">
                                <path
                                    d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z">
                                </path>
                                <rect x="2" y="9" width="4" height="12"></rect>
                                <circle cx="4" cy="4" r="2"></circle>
                            </svg>
                        </button>

                        <!-- WhatsApp -->
                        <button onclick="shareContent('whatsapp')" class="share-action" title="Share on WhatsApp">
                            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24"
                                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                stroke-linejoin="round">
                                <path
                                    d="M21 11.5a8.38 8.38 0 0 1-.9 3.8 8.5 8.5 0 0 1-7.6 4.7 8.38 8.38 0 0 1-3.8-.9L3 21l1.9-5.7a8.38 8.38 0 0 1-.9-3.8 8.5 8.5 0 0 1 4.7-7.6 8.38 8.38 0 0 1 3.8-.9h.5a8.48 8.48 0 0 1 8 8v.5z">
                                </path>
                            </svg>
                        </button>

                        <!-- Instagram / Copy Link -->
                        <button onclick="shareContent('instagram')" class="share-action" title="Share / Copy Link">
                            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24"
                                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                stroke-linejoin="round">
                                <circle cx="18" cy="5" r="3"></circle>
                                <circle cx="6" cy="12" r="3"></circle>
                                <circle cx="18" cy="19" r="3"></circle>
                                <line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line>
                                <line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line>
                            </svg>
                        </button>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="container text-center">
            <p>&copy; 2026 Taktik Eğitim Akademisi. All Rights Reserved.</p>
        </div>
    </footer>
    <script src="../main.js"></script>
</body>

</html>